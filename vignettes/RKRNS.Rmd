---
title: "BOLD decoding with the RKRNS package"
bibliography: REFERENCES.bib
output:
  pdf_document:
    toc: true
    highlight: zenburn
  ioslides_presentation:
    incremental: false
    widescreen: true
    smaller: false
  html_document:
    toc: true
    theme: readable
---

# Introduction

Decoding from blood oxygenation-level dependent (BOLD) magnetic resonance imaging (MRI) data 
remains an esoteric art.  Relatively few public datasets exist and these are rarely accompanied 
by accessible and validated, general-purpose decoding methodology.  This package seeks to 
document some relatively standard approaches to processing BOLD data and follow with a few 
novel extensions.  These are implemented via *R*, its packages and *ANTsR*.


## RKRNS Algorithms 

This package employs several algorithms for different aspects of BOLD processing

- hemodynamic response function estimation: based on GLMdenoise (@Kay2013) and conversations 
  with Kendrick Kay;

- registration and utilities for image processing: ANTs (@Tustison2014) and ANTsR (@ANTsR);

- core image processing and I/O: ITK (@Avants2014a);

- dimensionality reduction: Eigenanatomy (@Dhillon2014) and SCCAN (@Avants2014);

- temporal filtering via *R* packages.

In combination, these tools enable one to go from near-raw medical imaging data 
to a BOLD decoding experiment.  

## Data organization expected by RKRNS

We make several assumptions about data organization 
with this package.

- the stimulus matrix matches the bold matrix 

- the ...

XXX 

# Decoding in simulated data

## Example BOLD Data

We adapted methods from the *neuRosim* (@neuRosim) package in order to simulate 
event-related BOLD data.  This data involves a 4-class decoding task wherein one 
seeks to identify brain responses to novel faces, famous faces and their first 
and second presentations to the subject.  We distribute the underlying anatomical 
BOLD data along with a cortical mask within the package.  The data may be 
loaded by:
```{r simdata}
fn<-paste(path.package("RKRNS"),"/extdata/111157_mocoref_masked.nii.gz",sep="") 
eximg<-antsImageRead(fn,3)
fn<-paste(path.package("RKRNS"),"/extdata/subaal.nii.gz",sep="") 
mask<-antsImageRead(fn,3)
```
which gives you both the cortical `mask` and the example BOLD signal 
image `eximg`.  ANTsR also provides AAL label (@Tzourio-Mazoyer2002) names via:
```{r aal}
data(aal,package='ANTsR')
labs<-1:90
```
with cortical labs defined by `labs`.

## Run the simulation
We generate simulated bold data as in neuRosim.  
The `simulateBOLD` function results in a bold image 
in the `antsImage` class.  We subsequently convert 
this image to a $n\times p$ matrix where there are 
$n$ time volumes and $p$ voxels in the mask.
```{r simb}
bb<-simulateBOLD(option="henson",eximg=eximg,mask=mask)
mat<-timeseries2matrix( bb$simbold, bb$mask )
```
The data frame containing the bold image also 
contains the ... FIXME

Perform some diagnostic visualizations on the data.
```{r simbviz}
randvox<-sample(1:ncol(mat),4)
plot(ts(mat[,randvox]))
```

## Frequency filtering
Let's get rid of high frequency noise.
```{r ffilt}
# only filter high frequencies 1/(2*tr)
filtmat<-filterfMRI4KRNS( data.matrix(mat), tr=1, NA, NA, trendfrequency=2, trendfrequency2=NA )
plot(ts(filtmat[,randvox]))
```
We can eliminate low frequency contamination with polynomial regressors 
and other denoising techniques at a later step.

## Autoregression 
Probably not good for decoding, but 
we can also model autoregression coefficients.
```{r arfilt}
armat<-arCorrection( mat )
print(armat$arcoefs)
plot(ts(armat$outmat[,randvox]))
```

## Estimate $\beta$ values for each event
We estimate a $\beta^i$ vector for each of $i \in 1 \cdots q$ events.
This vector contains a scalar $\beta$ value for each voxel,
i.e. $\beta_j^i$ where $j \in 1 \cdots p$.

# Real data processing with RKRNS

We recommend that you motion correct the data 
before you use RKRNS tools.  This should be done 
once and done well.  Good approaches exist in *ANTsR* 
which yield both motion matrices and relevant summary 
measurements such as FD and DVARS.  See `?antsPreprocessfMRI` 
for a simplified utility function.  This function could be 
used on each run of an experiment and the results stored 
in organized fashion for later use. 

## BOLD assembly 

## BOLD preprocessing

## BOLD signal characteristics 

BOLD signal is information rich but noisy.  We employ three
fundamental aspects of BOLD to guide our preprocessing choices:

- Physiological noise contaminates the BOLD signal ( see compcor @Behzadi2007 )
- The BOLD response is slow ( > 5 seconds ) after a stimulus
- The response has limited temporal extent ( < 25 seconds )

## Processing decisions
```{r filtering}
afilterlowfrequency<-4
afilterhighfrequency<-20
```
Our processing therefore uses the following steps:

1. Assemble the BOLD blocks to match the overall event-related design file 
    - optionally use anatomical labeling to select subregions for assembly
    - preliminary studies use language network regions: `r aal$label_name[labs]`.
1. Learn physiological noise parameters from 1 block and apply them to the rest
1. Filter the fMRI with a Butterworth band-pass filter, extracting select mid-range frequencies
    - low frequency is `r afilterlowfrequency`
    - high frequency is `r afilterhighfrequency`
1. model sentence length effects (& motion---TODO) by linear regression

## Training & testing

Once these steps are complete we choose a training
and testing split and perform statistical modeling.

# Multivariate statistical modeling

## Formulation

Convert the BOLD to a spatiotemporal representation.  This model is of the form:

$$ Z_k = w + w_{00} x_{00} + w_{01} x_{01} + \cdots + 
 w_{0p} x_{0p} + w_{10} x_{10} + \cdots + w_{tp} x_{tp} + \epsilon$$

where $w$ represents a weighting term, $Z_k$ represents a multivariate outcome (an
_eigensentence_) at time k, $x_{lm}$ represents a BOLD measurement at time $l$
and space $m$ and $t$ represents the maximum temporal index within a
short window near event $Z_k$. 

## Matrix formulation

So, if $t=0$, then the global time
index is $k$; if $t=1$, the global time index is $k+1$, etcetera.
This formulation allows us to simultaneously model and/or select
variables in space-time.  From here, we denote the right side of the 
above equation (for all $k$) as $XW^T$ where $X$ 
has dimensions $n \times p$ and $W$ has dimensions $k \times p$. 
Similarly, $Z$ is a matrix of
_eigensentence_ representations with dimension $n \times q$. 

## Sparse canonical correlation between space-time BOLD and eigenwords

CCA maximizes $PearsonCorrelation( XW^T, ZY^T )$ where $X, W$ are as above and $Z$
and $Y$ are similarly defined.  CCA optimizes the matrices $W, Y$
operating on $X, Z$ to find a low-dimensional representation of the
data pair $( X , Z )$ in which correlation is maximal.  Following
ideas outlined in @Dhillon2014 and @Avants2014, this method can be
extended with sparsity constraints that yield rows of $W, Y$ with a
controllable number of non-zero entries.

## Predictive model

Given CCA solution matrix $W$, one may employ the low-dimensional
representation, $XW^T$, in multi-label classification.  Currently, we
employ SVM or random forests as multi-label learners for the problem:

$$L_i = f( XW^T ),$$

that is, learning a (sentence) label function from the BOLD data.

(actually, this is a WIP so do not take this too seriously --- see below )

# Study Methodology and Preliminary Validation

Here, we set up parameters for the study, including label sets and temporal filtering.
We can use Brodmann or AAL label sets with the current data though others can easily be added. 
The current parameters select brain regions related to heteromodal association and language.

# References
