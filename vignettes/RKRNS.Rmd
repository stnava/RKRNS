---
title: "Introduction to decoding with the RKRNS package"
bibliography: REFERENCES.bib
output:
  pdf_document:
    toc: true
    highlight: zenburn
  ioslides_presentation:
    incremental: false
    widescreen: true
    smaller: false
  html_document:
    toc: true
    theme: readable
---
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Intro to RKRNS}
  revealjs_presentation:
    theme: sky
    transition: fade
    highlight: pygments
    center: true
    incremental: true
-->

# Introduction

# BOLD preprocessing

## BOLD signal characteristics 

BOLD signal is information rich but noisy.  We employ three
fundamental aspects of BOLD to guide our preprocessing choices:

- Physiological noise contaminates the BOLD signal ( see compcor @Behzadi2007 )
- The BOLD response is slow ( > 5 seconds ) after a stimulus
- The response has limited temporal extent ( < 25 seconds )

## Processing decisions

Our processing therefore uses the following steps:

1. Assemble the BOLD blocks to match the overall event-related design file 
    - optionally use anatomical labeling to select subregions for assembly
    - preliminary studies use language network regions: `r aal$label_name[labs]`.
1. Learn physiological noise parameters from 1 block and apply them to the rest
1. Filter the fMRI with a Butterworth band-pass filter, extracting select mid-range frequencies
    - low frequency is `r afilterlowfrequency`
    - high frequency is `r afilterhighfrequency`
1. model sentence length effects (& motion---TODO) by linear regression

## Training & testing

Once these steps are complete we choose a training
and testing split and perform statistical modeling.

# Multivariate statistical modeling

## Formulation

Convert the BOLD to a spatiotemporal representation.  This model is of the form:

$$ Z_k = w + w_{00} x_{00} + w_{01} x_{01} + \cdots + 
 w_{0p} x_{0p} + w_{10} x_{10} + \cdots + w_{tp} x_{tp} + \epsilon$$

where $w$ represents a weighting term, $Z_k$ represents a multivariate outcome (an
_eigensentence_) at time k, $x_{lm}$ represents a BOLD measurement at time $l$
and space $m$ and $t$ represents the maximum temporal index within a
short window near event $Z_k$. 

## Matrix formulation

So, if $t=0$, then the global time
index is $k$; if $t=1$, the global time index is $k+1$, etcetera.
This formulation allows us to simultaneously model and/or select
variables in space-time.  From here, we denote the right side of the 
above equation (for all $k$) as $XW^T$ where $X$ 
has dimensions $n \times p$ and $W$ has dimensions $k \times p$. 
Similarly, $Z$ is a matrix of
_eigensentence_ representations with dimension $n \times q$. 

## Sparse canonical correlation between space-time BOLD and eigenwords

CCA maximizes $PearsonCorrelation( XW^T, ZY^T )$ where $X, W$ are as above and $Z$
and $Y$ are similarly defined.  CCA optimizes the matrices $W, Y$
operating on $X, Z$ to find a low-dimensional representation of the
data pair $( X , Z )$ in which correlation is maximal.  Following
ideas outlined in @Dhillon2014 and @Avants2014, this method can be
extended with sparsity constraints that yield rows of $W, Y$ with a
controllable number of non-zero entries.

## Predictive model

Given CCA solution matrix $W$, one may employ the low-dimensional
representation, $XW^T$, in multi-label classification.  Currently, we
employ SVM or random forests as multi-label learners for the problem:

$$L_i = f( XW^T ),$$

that is, learning a (sentence) label function from the BOLD data.

(actually, this is a WIP so do not take this too seriously --- see below )

# Study Methodology and Preliminary Validation

Here, we set up parameters for the study, including label sets and temporal filtering.
We can use Brodmann or AAL label sets with the current data though others can easily be added. 
The current parameters select brain regions related to heteromodal association and language.

# References


